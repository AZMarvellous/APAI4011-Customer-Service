2024-12-10 13:58:44.261 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 13:58:44.267 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 13:58:44.268 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 13:58:44.269 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 13:58:44.270 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:08:56.044 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:08:56.056 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:08:56.057 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:08:56.058 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:08:56.059 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:08:56.062 | SUCCESS  | __main__:init:47 - 开始初始化项目数据目录：/home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data
2024-12-10 14:08:56.062 | SUCCESS  | __main__:init:49 - 创建所有数据目录：成功。
2024-12-10 14:08:56.065 | SUCCESS  | __main__:init:52 - 复制 samples 知识库文件：成功。
2024-12-10 14:08:56.078 | SUCCESS  | __main__:init:54 - 初始化知识库数据库：成功。
2024-12-10 14:08:56.393 | SUCCESS  | __main__:init:66 - 生成默认配置文件：成功。
2024-12-10 14:08:56.393 | SUCCESS  | __main__:init:67 - 请先检查确认 model_settings.yaml 里模型平台、LLM模型和Embed模型信息已经正确
2024-12-10 14:08:56.393 | SUCCESS  | __main__:init:76 - 执行 chatchat kb -r 初始化知识库，然后 chatchat start -a 启动服务。
2024-12-10 14:09:20.033 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:20.049 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:20.059 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:20.068 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:20.078 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:21.465 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:21.486 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:21.496 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:21.506 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:21.516 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:21.537 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:09:21.538 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:09:31.981 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:31.999 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:32.010 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:32.020 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:32.029 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:33.388 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:33.408 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:33.418 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:33.428 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:33.438 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:33.459 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:09:33.461 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:09:34.757 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:34.775 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:34.784 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:34.794 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:34.804 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:34.818 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:35.298 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.299 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.299 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.299 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.314 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.380 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.515 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:35.557 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.567 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.577 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.587 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:35.718 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:09:37.013 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:37.030 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:37.040 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:37.049 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:37.059 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:37.061 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:09:59.340 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:59.350 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:59.360 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:09:59.842 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:59.844 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:09:59.846 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:09:59.846 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:09:59.846 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:09:59.857 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:59.858 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:59.858 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:09:59.859 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:10:44.481 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:10:44.482 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:10:44.482 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:10:44.483 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:16:55.631 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:16:56.040 | INFO     | chatchat.server.knowledge_base.kb_cache.faiss_cache:load_vector_store:109 - loading vector store in 'samples/vector_store/bge-m3' from disk.
2024-12-10 14:16:56.659 | INFO     | chatchat.server.knowledge_base.kb_cache.faiss_cache:load_vector_store:109 - loading vector store in 'samples/vector_store/bge-m3' from disk.
2024-12-10 14:16:56.817 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/大模型指令对齐训练原理.md
2024-12-10 14:16:56.818 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/大模型应用技术原理.md
2024-12-10 14:16:56.819 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/大模型推理优化策略.md
2024-12-10 14:16:56.822 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/分布式训练技术原理.md
2024-12-10 14:16:56.825 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/大模型技术栈-实战与应用.md
2024-12-10 14:16:56.825 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - TextLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/大模型技术栈-算法与原理.md
2024-12-10 14:16:56.826 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - UnstructuredFileLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/test.txt
2024-12-10 14:16:56.827 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - UnstructuredExcelLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/langchain-ChatGLM_open.xlsx
2024-12-10 14:16:56.827 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - CSVLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/langchain-ChatGLM_open.csv
2024-12-10 14:16:56.827 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - UnstructuredExcelLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/langchain-ChatGLM_closed.xlsx
2024-12-10 14:16:56.828 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - RapidOCRPDFLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/langchain.pdf
2024-12-10 14:16:56.829 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - CSVLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/samples/content/test_files/langchain-ChatGLM_closed.csv
2024-12-10 14:17:02.080 | WARNING  | chatchat.init_database:main:157 - Caught KeyboardInterrupt! Setting stop event...
2024-12-10 14:18:24.195 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:25.537 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:25.605 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:18:25.607 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:18:26.881 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:26.945 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:27.597 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:27.792 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:18:29.152 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:29.201 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:18:32.856 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:32.857 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:32.859 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:32.860 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:32.860 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:18:32.869 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:32.869 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:32.869 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:32.870 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:18:53.013 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.014 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.014 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.014 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:18:53.159 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.160 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.160 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.160 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:18:53.182 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.182 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.182 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:53.183 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:18:54.298 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:54.299 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:54.299 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:18:54.299 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:00.070 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.070 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.070 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.070 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:00.095 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.096 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.096 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:00.096 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:01.210 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:01.211 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:01.211 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/update_info: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:01.211 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:15.004 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:15.005 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:15.006 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:15.006 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:16.514 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:16.517 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:16.517 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:16.517 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:20.185 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:20.186 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:20.187 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:20.187 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:19:34.337 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:34.340 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:34.341 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/create_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:19:34.341 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:20:16.288 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:16.289 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:16.289 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:16.289 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:20:37.802 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:20:37.803 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:20:37.803 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:20:37.804 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:20:45.507 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:46.827 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:46.894 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:20:46.896 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:20:48.159 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:48.219 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:48.879 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:49.074 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:20:50.352 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:50.401 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:20:51.344 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.345 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.348 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.348 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.348 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:20:51.357 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.357 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.357 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.358 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.699 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.700 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.702 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.702 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:20:51.702 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:20:51.710 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.710 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.711 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:20:51.711 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:26:46.965 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:26:46.967 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:26:46.969 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:26:46.969 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:26:46.970 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:26:46.979 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:26:46.980 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:26:46.980 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:26:46.980 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 14:33:17.900 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:17.922 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:17.932 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:17.942 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:17.951 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:19.204 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:19.220 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:19.230 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:19.239 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:19.249 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:19.271 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:33:19.272 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:33:20.558 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:20.576 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:20.585 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:20.595 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:20.605 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:20.618 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:21.077 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.077 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.077 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.077 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.091 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.149 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.260 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:21.297 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.309 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.318 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.328 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:21.454 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:33:22.890 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:22.911 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:22.921 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:22.931 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:22.940 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:33:22.943 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:33:56.537 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:56.541 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:33:56.544 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:33:56.544 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:33:56.544 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:33:56.558 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:56.558 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:56.558 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:33:56.559 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:34:28.431 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:34:28.432 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:34:28.432 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:34:28.432 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:34:38.096 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:34:38.119 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:34:38.129 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:34:38.139 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:34:38.149 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:11.390 | ERROR    | chatchat.startup:start_main_server:310 - 'WEBUI Server (1653740)'
2024-12-10 14:35:11.391 | WARNING  | chatchat.startup:start_main_server:311 - Caught KeyboardInterrupt! Setting stop event...
2024-12-10 14:35:11.391 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:35:11.392 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:35:11.393 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:35:11.393 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:35:24.493 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:24.514 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:24.524 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:24.534 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:24.544 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:25.860 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:25.880 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:25.889 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:25.899 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:25.909 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:25.932 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:35:25.934 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:35:27.244 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:27.261 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.271 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.280 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.290 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.304 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:27.790 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.790 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.790 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.790 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.805 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.865 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:27.982 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:28.022 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:28.032 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:28.041 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:28.051 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:28.176 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:35:29.499 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:29.516 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:29.525 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:29.535 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:29.545 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:29.547 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:35:30.139 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:30.149 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:30.159 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:30.579 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:30.580 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:30.583 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:30.583 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:30.583 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:30.593 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:30.593 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:30.593 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:30.593 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:35.052 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:35.053 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:35.055 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:35.055 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:35.055 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:35.065 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:35.065 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:35.065 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:35.065 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:37.093 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:37.101 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:37.103 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:37.103 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:37.103 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:37.865 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:37.865 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:37.865 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:37.865 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:35:38.006 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:38.013 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.015 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.015 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.015 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:38.565 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:38.573 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.575 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.575 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:38.575 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:39.131 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:35:39.137 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:39.139 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:39.139 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /knowledge_base/list_knowledge_bases: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:39.139 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:55.963 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:55.963 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:55.964 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:55.964 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:35:59.114 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:59.114 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:59.114 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:35:59.115 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:36:26.429 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:36:26.430 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:36:26.430 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:36:26.431 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:36:34.674 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:34.695 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:34.705 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:34.715 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:34.725 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:35.067 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:35.067 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:35.067 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:35.067 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:35.087 | INFO     | chatchat.server.knowledge_base.kb_cache.faiss_cache:load_vector_store:109 - loading vector store in 'samples/vector_store/quentinz/bge-large-zh-v1.5' from disk.
2024-12-10 14:36:35.106 | ERROR    | chatchat.server.knowledge_base.kb_cache.faiss_cache:load_vector_store:140 - Error raised by inference API HTTP code: 404, {"error":"model \"quentinz/bge-large-zh-v1.5\" not found, try pulling it first"}
2024-12-10 14:36:35.107 | ERROR    | chatchat.init_database:worker:61 - 向量库 samples 加载失败。
2024-12-10 14:36:47.244 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:47.265 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:47.275 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:47.285 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:47.295 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:48.570 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:48.589 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:48.599 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:48.609 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:48.619 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:48.643 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:36:48.645 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:36:49.938 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:49.957 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:49.969 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:49.978 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:49.988 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.003 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:50.479 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.479 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.480 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.480 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.494 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.554 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.677 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:50.720 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.730 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.740 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.750 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:50.882 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:36:52.232 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:52.250 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:52.260 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:52.270 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:52.280 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:52.282 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:36:54.500 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:54.512 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:54.522 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:36:54.993 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:54.994 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:36:54.997 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:36:54.997 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:36:54.997 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:36:55.009 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:55.009 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:55.009 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:36:55.009 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:07.942 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:07.942 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:07.942 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:07.942 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:14.146 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:14.146 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:14.146 | ERROR    | chatchat.webui_pages.utils:post:87 - TypeError: error when post /knowledge_base/delete_knowledge_base: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:14.146 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:37:21.345 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:21.345 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:37:33.067 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.068 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.070 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.070 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.071 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:37:33.081 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.081 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.081 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.081 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.625 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.626 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.628 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.628 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:33.628 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:37:33.638 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.638 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.638 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:33.638 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:35.203 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:35.204 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:35.206 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:35.206 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:37:35.206 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:37:35.216 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:35.216 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:35.216 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:35.216 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:37:58.440 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:37:58.441 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:37:58.441 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:37:58.442 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:38:01.708 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:01.730 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:01.740 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:01.750 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:01.760 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:03.064 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:03.082 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:03.092 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:03.101 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:03.111 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:03.133 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:38:03.135 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:38:04.347 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:04.364 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.374 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.383 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.393 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.406 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:04.862 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.862 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.862 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.863 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.876 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:04.934 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:05.046 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:05.084 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:05.094 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:05.104 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:05.113 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:05.242 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:38:06.574 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:06.592 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:06.601 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:06.611 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:06.620 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:06.623 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:38:07.093 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:07.103 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:07.113 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:38:07.514 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:07.516 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:38:07.517 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:38:07.518 | ERROR    | chatchat.webui_pages.utils:get:64 - TypeError: error when get /tools: Client.__init__() got an unexpected keyword argument 'proxies'
2024-12-10 14:38:07.518 | ERROR    | chatchat.webui_pages.utils:to_json:233 - AttributeError: API未能返回正确的JSON。'NoneType' object has no attribute 'json'
2024-12-10 14:38:07.527 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:07.527 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:07.527 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:07.528 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:38:48.970 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:38:48.971 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 14:38:48.971 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:38:48.972 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 14:45:07.918 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:07.940 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:07.950 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:07.961 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:07.971 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:09.317 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:09.334 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:09.344 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:09.354 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:09.363 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:09.385 | INFO     | chatchat.startup:start_main_server:256 - 正在启动服务：
2024-12-10 14:45:09.386 | INFO     | chatchat.startup:start_main_server:257 - 如需查看 llm_api 日志，请前往 /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/logs
2024-12-10 14:45:10.716 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:10.732 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:10.743 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:10.752 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:10.761 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:10.774 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:11.234 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.234 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.234 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.234 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.247 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.372 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.425 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:11.465 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.475 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.485 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.494 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:11.620 | INFO     | chatchat.startup:run_api_server:54 - Api MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:45:13.008 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:13.024 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:13.034 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:13.044 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:13.053 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:13.056 | INFO     | chatchat.startup:run_webui:79 - Webui MODEL_PLATFORMS: [PlatformConfig(platform_name='xinference', platform_type='xinference', api_base_url='http://127.0.0.1:9997/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=True, llm_models=[], embed_models=[], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='ollama', platform_type='ollama', api_base_url='http://127.0.0.1:11434/v1', api_key='EMPTY', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['qwen:7b', 'qwen2:7b'], embed_models=['quentinz/bge-large-zh-v1.5'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='oneapi', platform_type='oneapi', api_base_url='http://127.0.0.1:3000/v1', api_key='sk-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['chatglm_pro', 'chatglm_turbo', 'chatglm_std', 'chatglm_lite', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'ERNIE-Bot', 'ERNIE-Bot-turbo', 'ERNIE-Bot-4', 'SparkDesk'], embed_models=['text-embedding-v1', 'Embedding-V1'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[]), PlatformConfig(platform_name='openai', platform_type='openai', api_base_url='https://api.openai.com/v1', api_key='sk-proj-', api_proxy='', api_concurrencies=5, auto_detect_model=False, llm_models=['gpt-4o', 'gpt-3.5-turbo'], embed_models=['text-embedding-3-small', 'text-embedding-3-large'], text2image_models=[], image2text_models=[], rerank_models=[], speech2text_models=[], text2speech_models=[])]
2024-12-10 14:45:21.482 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:21.493 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:21.503 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:22.017 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:22.067 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:22.067 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:22.067 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:22.068 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:24.816 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:25.379 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:45:25.832 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:25.833 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:25.833 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:25.833 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:30.014 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:30.014 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:31.247 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:45:31.248 | WARNING  | chatchat.server.utils:get_default_embedding:214 - default embedding model bge-m3 is not found in available embeddings, using quentinz/bge-large-zh-v1.5 instead
2024-12-10 14:46:26.164 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:46:26.341 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 14:46:28.772 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using qwen:7b instead
2024-12-10 15:22:25.472 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:25.536 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:25.536 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:25.536 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:25.536 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:33.350 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:33.558 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:22:34.937 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 15:58:44.725 | INFO     | chatchat.server.knowledge_base.kb_cache.faiss_cache:load_vector_store:109 - loading vector store in 'Customer Service/vector_store/bge-m3' from disk.
2024-12-10 15:59:23.483 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - RapidOCRDocLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/Customer Service/content/metadata analysis result.docx
2024-12-10 15:59:23.484 | INFO     | chatchat.server.knowledge_base.utils:file2docs:336 - RapidOCRDocLoader used for /home/angus/apai4011-build/Langchain-Chatchat/libs/chatchat-server/langchain-data/data/knowledge_base/Customer Service/content/Uer review analysis result.docx
2024-12-10 15:59:28.689 | INFO     | chatchat.server.knowledge_base.kb_cache.faiss_cache:save:40 - 已将向量库 ('Customer Service', 'bge-m3') 保存到磁盘
2024-12-10 16:00:35.807 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:35.851 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:35.851 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:35.852 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:35.853 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:36.031 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:36.068 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:36.068 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:36.068 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:36.068 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:40.023 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:40.062 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:40.062 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:40.063 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:00:40.063 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:32.140 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:32.181 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:32.182 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:32.183 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:32.183 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:36.987 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:37.332 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:03:39.983 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:06:58.665 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:07:22.584 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:04.895 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:08.159 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:08.429 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:09.364 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:13.466 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:13.741 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:23.431 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:23.939 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:25.353 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:25.860 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:26.492 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:26.881 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:28.140 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:28.717 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:29.072 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:08:35.058 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:09:15.582 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:09:19.327 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:09:19.753 | WARNING  | chatchat.server.chat.kb_chat:knowledge_base_chat_iterator:218 - streaming progress has been interrupted by user.
2024-12-10 16:09:19.776 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:09:25.976 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:09:56.171 | WARNING  | chatchat.server.utils:get_default_llm:205 - default llm model glm4-chat is not found in available llms, using llama-3.1-instruct instead
2024-12-10 16:34:54.553 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 16:34:54.554 | WARNING  | chatchat.startup:start_main_server:314 - Sending SIGKILL to %s
2024-12-10 16:34:54.555 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
2024-12-10 16:34:54.555 | INFO     | chatchat.startup:start_main_server:325 - Process status: %s
